# Machine Learning 2019 and before

| Year |                                                Title                                                |    Author     | Publication |                                                Code                                                | Tags | Notes | Datasets|
|:----:|:---------------------------------------------------------------------------------------------------:|:-------------:|:-----------:|:--------------------------------------------------------------------------------------------------:|:----:|:-----:|:-----:|
| 2019 | [Annotation cost-sensitive active learning by tree sampling](https://link.springer.com/content/pdf/10.1007/s10994-019-05781-7.pdf) |  Tsou and Lin  | Machine Learning |                            -                             |  `classification`    | `hierarchical sampling algorithm`, `Decision tree algorithm`,`None`, `Tra`, `Hard`      |     liver, vote, breast, diabetes, german, mashroom, adult, seeds, knowledge, vehicle, nursey, yeast  |    annotation cost-sensitive active learning algorithms, which need to estimate the utility and cost of each query simultaneously. We propose a novel algorithm, the cost-sensitive tree sampling algorithm, that conducts the two estimation tasks together and solve it with a tree-structured model motivated from hierarchical sampling, a famous algorithm for traditional active learning.   |
| 2019 | [Nuclear discrepancy for single-shot batch active learning](https://link.springer.com/content/pdf/10.1007/s10994-019-05817-y.pdf)  | Viering et al. | Machine Learning | [code](https://github.com/tomviering/NuclearDiscrepancy) |   `classification`   | `representative`,`SVMs`, `None`, `Tra`, `Hard`      |  MNIST     |   single-shot active learners that minimize generalization bounds to select a representative sample, such as the maximum mean discrepancy (MMD) active learner.     |
