# ICDM 2019 and before

| Year |                                                       Title                                                       |   Author    | Publication | Code | Tasks | Notes | Datasets| Notions |
|:----:|:-----------------------------------------------------------------------------------------------------------------:|:-----------:|:-----------:|:----:|:----:|:-----:|:-----:|:-----:|
| 2019 |                       [Learning to Sample: An Active Learning Framework](https://www.computer.org/csdl/proceedings-article/icdm/2019/460400a538/1h5XFC1YGxG)                        | Shao et al. |    ICDM     |  -   |   classification (image classification, salary level prediction, and entity resolution.)   | `Hybrid (uncertainty and diversity)`, `DNNs`,   `Meta-learning`,`None`, `Hard`   |  Cora, NCVoter, DBLP-ACM, DBLP-Scholar     |   The unavailability of large amounts of labeled samples for training meta-learning models would inevitably lead to poor performance    |
| 2017 |         [Deep Similarity-Based Batch Mode Active Learning with Exploration-Exploitation](https://www.computer.org/csdl/proceedings-article/icdm/2017/3835a575/12OmNzRHOTj)          | Yin et al.  |    ICDM     |  -   |   Classification   | `Hybrid`, `DNNs`, `Exploration`, `Tra`, `Hard`     |    MNIST   |       |
| 2017 | [AnySCAN: An Efficient Anytime Framework with Active Learning for Large-Scale Network Clustering](https://www.computer.org/csdl/proceedings-article/icdm/2017/3835a665/12OmNykTNoc) | Zhao et al. |    ICDM     |  -   |   Large-scale Network Clustering   |   `informative`, `DNNs`, `None`, `Tra`, `Hard`    |   Real-world, Synthetic    |       |
